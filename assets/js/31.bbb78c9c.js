(window.webpackJsonp=window.webpackJsonp||[]).push([[31],{525:function(t,e,r){"use strict";r.r(e);var a=r(18),o=Object(a.a)({},(function(){var t=this,e=t.$createElement,r=t._self._c||e;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("h2",{attrs:{id:"_1-通信模型"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_1-通信模型"}},[t._v("#")]),t._v(" 1 通信模型")]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/68822c6c2a59844ed62d290f54c64a49.png"}}),t._v(" "),r("table",[r("thead",[r("tr",[r("th",{staticStyle:{"text-align":"left"}},[t._v("名称")]),t._v(" "),r("th",{staticStyle:{"text-align":"left"}},[t._v("解释")])])]),t._v(" "),r("tbody",[r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("Broker")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("消息中间件处理节点，一个Kafka节点就是一个broker，一个或者多个Broker可以组成一个Kafka集群")])]),t._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("Topic")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("Kafka根据topic对消息进行归类，发布到Kafka集群的每条消息都需要指定一个topic")])]),t._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("Partition")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("物理上的概念，一个topic可以分为多个partition，每个partition内部消息是有序的")])]),t._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("Consumer")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("消息消费者，从Broker读取消息的客户端")])]),t._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("ConsumerGroup")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("每个Consumer属于一个特定的Consumer Group，一条消息可以被多个不同的Consumer Group消费，但是一个Consumer Group中只能有一个Consumer能够消费该消息")])]),t._v(" "),r("tr",[r("td",{staticStyle:{"text-align":"left"}},[t._v("Producer")]),t._v(" "),r("td",{staticStyle:{"text-align":"left"}},[t._v("消息生产者，向Broker发送消息的客户端")])])])]),t._v(" "),r("h2",{attrs:{id:"_2-概念"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-概念"}},[t._v("#")]),t._v(" 2 概念")]),t._v(" "),r("h3",{attrs:{id:"_2-1-topic-partition"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-topic-partition"}},[t._v("#")]),t._v(" 2.1 Topic & Partition")]),t._v(" "),r("ul",[r("li",[t._v("每个partition，都对应一个commit log文件。")]),t._v(" "),r("li",[t._v("每个partition都有一个唯一编号：offset。")]),t._v(" "),r("li",[t._v("每个consumer都是基于自己在commit log中的offset进行工作的。Offset由consumer自己维护。")])]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/cd889f9c64107209dd5e8827749d95ec.png",width:"50%"}}),t._v(" "),r("p",[r("strong",[t._v("为什么topic数据要分区存储？")])]),t._v(" "),r("p",[t._v("1、分区之后可以将不同的分区放在不同的机器上，相当于对数据做了分布式存储")]),t._v(" "),r("p",[t._v("2、提高并行度")]),t._v(" "),r("p",[t._v("数据存储：server.properties log.dirs=/usr/local/data/kafka-logs")]),t._v(" "),r("p",[t._v("Kafka Broker 有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是 1GB。")]),t._v(" "),r("p",[t._v("一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做 log rolling，正在被写入的那个日志段文件，叫做 active log segment。")]),t._v(" "),r("h3",{attrs:{id:"_2-2-consumer-consumergroup"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-consumer-consumergroup"}},[t._v("#")]),t._v(" 2.2 Consumer & ConsumerGroup")]),t._v(" "),r("ul",[r("li",[t._v("一个partition同一个时刻在一个consumer group中只能有一个consumer在消费，从而保证消费顺序。")]),t._v(" "),r("li",[t._v("consumer group中的consumer的数量不能比一个Topic中的partition的数量多，否则多出来的consumer消费不到消息。")])]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/d234005bff9c889150587ca02e0265a9.png",width:"50%"}}),t._v(" "),r("p",[t._v("Kafka只在partition的范围内保证消息消费的局部顺序性，不能在同一个topic中的多个partition中保证总的消费顺序性。")]),t._v(" "),r("p",[t._v("如果有在总体上保证消费顺序的需求，那么我们可以通过将topic的partition数量设置为1，将consumer group中的consumer instance数量也设置为1，但是这样会影响性能，所以kafka的顺序消费很少用。")]),t._v(" "),r("h3",{attrs:{id:"_2-3-producer"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-producer"}},[t._v("#")]),t._v(" 2.3 Producer")]),t._v(" "),r("p",[r("strong",[t._v("写入方式")])]),t._v(" "),r("p",[t._v("producer 采用 push 模式将消息发布到 broker，每条消息都是被append到patition中，属于顺序写磁盘")]),t._v(" "),r("p",[r("strong",[t._v("消息路由")])]),t._v(" "),r("p",[t._v("producer发送消息到broker时，会根据分区算法选择将其存储到哪一个partition。其路由机制为：")]),t._v(" "),r("p",[t._v("1.指定了patition，则直接使用；")]),t._v(" "),r("p",[t._v("2.未指定patition 但指定key，通过对key的value进行hash选出一个patition。")]),t._v(" "),r("p",[t._v("3.patition和key都未指定，使用轮询选出一个patition。")]),t._v(" "),r("p",[r("strong",[t._v("消息确认机制")])]),t._v(" "),r("p",[r("strong",[t._v("acks=0")]),t._v("：表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。")]),t._v(" "),r("p",[r("strong",[t._v("acks=1")]),t._v("：至少要等待leader已经成功将数据写入本地log，但不需要等待所有follower是否成功写入。")]),t._v(" "),r("p",[r("strong",[t._v("acks=-1或all")]),t._v("：leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志")]),t._v(" "),r("p",[r("strong",[t._v("acks=-1时的数据流程：")])]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/5b8027bb58f1eff3df2f06db64ddbb01.png",width:"70%"}}),t._v(" "),r("p",[t._v('1.producer先从zookeeper 的 "/brokers/.../state" 节点找到该partition的leader。')]),t._v(" "),r("p",[t._v("2.producer将消息发送给该leader。")]),t._v(" "),r("p",[t._v("3.leader将消息写入本地log。")]),t._v(" "),r("p",[t._v("4.followers从leader pull消息，写入本地log后向leader发送ACK。")]),t._v(" "),r("p",[t._v("5.leader收到"),r("strong",[t._v("所有ISR中")]),t._v("的replica的ACK后，增加HW（high watermark，最后 commit 的 offset）并向producer发送ACK。")]),t._v(" "),r("h2",{attrs:{id:"_3-选举机制"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_3-选举机制"}},[t._v("#")]),t._v(" 3 选举机制")]),t._v(" "),r("p",[r("strong",[t._v("Controller选举机制")])]),t._v(" "),r("p",[t._v("kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。")]),t._v(" "),r("p",[r("strong",[t._v("Partition副本选举Leader机制")])]),t._v(" "),r("p",[t._v("controller感知到分区leader所在的broker挂了，会从ISR列表里挑第一个broker作为leader")]),t._v(" "),r("p",[t._v("(参数unclean.leader.election.enable=false的前提下。")]),t._v(" "),r("p",[t._v("参数unclean.leader.election.enable为true，则ISR列表里所有副本都挂了的时候可以在ISR列表外的副本中选leader，")]),t._v(" "),r("p",[t._v("这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。)")]),t._v(" "),r("p",[r("strong",[t._v("副本进入ISR列表有两个条件:")])]),t._v(" "),r("p",[t._v("1.必须能与zookeeper保持会话以及跟leader副本网络连通")]),t._v(" "),r("p",[t._v("2.副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表)")]),t._v(" "),r("h2",{attrs:{id:"_4-hw与leo"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_4-hw与leo"}},[t._v("#")]),t._v(" 4 HW与LEO")]),t._v(" "),r("p",[t._v("LEO （Log End Offset）")]),t._v(" "),r("p",[t._v("HW有两个主要的作用：")]),t._v(" "),r("p",[t._v("1、用于实现副本备份机制（replication）；")]),t._v(" "),r("p",[t._v("2、定义消息可见性，即HW之下的所有消息对consumer是可见的。如果没有HW机制，就需要其他手段来实现这两个功能。")]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/3caf278f3fa5f0b33a8414ac0e65ae09.jpeg",width:"80%"}}),t._v(" "),r("h2",{attrs:{id:"_5-kafka核心总控制器controller"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_5-kafka核心总控制器controller"}},[t._v("#")]),t._v(" 5 kafka核心总控制器Controller")]),t._v(" "),r("p",[t._v("在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个集群中所有分区和副本的状态。")]),t._v(" "),r("p",[r("strong",[t._v("主题管理")])]),t._v(" "),r("p",[t._v("完成对Kafka主题的创建、删除以及分区增加的操作")]),t._v(" "),r("p",[r("strong",[t._v("分区重分配")])]),t._v(" "),r("p",[t._v("对已有主题分区进行细粒度的分配功能")]),t._v(" "),r("p",[r("strong",[t._v("集群成员管理")])]),t._v(" "),r("p",[t._v("自动检测新增Broker、Broker主动关闭、Broker宕机.")]),t._v(" "),r("p",[t._v("/brokers/ids/下面会存放Broker实例的id临时节点，当我们看到/brokers/ids下面有几个节点，就表示有多少个存活的Broker实例。")]),t._v(" "),r("p",[t._v("当Broker宕机时，临时节点就会被删除，此时控制器对应的监听器就会感知到Broker下线，进而完成对应的下线工作。")]),t._v(" "),r("p",[r("strong",[t._v("数据服务")])]),t._v(" "),r("p",[t._v("向其它Broker提供数据服务，控制器上保存了最全的集群元数据信息,")]),t._v(" "),r("p",[t._v("其它Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据")]),t._v(" "),r("h2",{attrs:{id:"_6-kafka高性能原因"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_6-kafka高性能原因"}},[t._v("#")]),t._v(" 6 kafka高性能原因")]),t._v(" "),r("ul",[r("li",[r("strong",[t._v("磁盘顺序读写")]),t._v("：kafka消息不能修改以及不会从文件中间删除保证了磁盘顺序读，kafka的消息写入文件都是追加在文件末尾。")]),t._v(" "),r("li",[t._v("**PageCache：**Kafka重度依赖底层操作系统提供的磁盘高速缓存PageCache（内核缓冲区）功能。"),r("br"),t._v("\n当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。内存池再异步地写到磁盘上。"),r("br"),t._v("\n当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。"),r("br"),t._v("\n实际上PageCache是把尽可能多的空闲内存都当做了磁盘缓存来使用。"),r("br"),t._v("\n同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS都支持PageCache。")]),t._v(" "),r("li",[t._v("**零拷贝：**linux操作系统 “零拷贝” 机制使用了sendfile方法， 允许操作系统将数据从Page Cache 直接发送到网络，只需要最后一步的copy操作将数据复制到 NIC 缓冲区， 这样避免重新复制数据 。通过这种 “零拷贝” 的机制，Page Cache 结合 sendfile 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。")])]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/654e570272d1d4edff52cd2997188a58.jpeg",width:"70%"}}),t._v(" "),r("ul",[r("li",[r("strong",[t._v("批量读写、批量压缩")])])]),t._v(" "),r("h2",{attrs:{id:"_7-线上规划"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#_7-线上规划"}},[t._v("#")]),t._v(" 7 线上规划")]),t._v(" "),r("img",{staticClass:"imgcss",attrs:{src:"http://media.luoxiaofeng.cn/blog/img/f8909a1dd7ff0e3dcaf6f2362890735c.png",width:"70%"}})])}),[],!1,null,null,null);e.default=o.exports}}]);